{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from utils.draw import draw_digits\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, 28, 28)\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.MNIST('data', download=True,\n",
    "                        transform=transforms.Compose([\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Lambda(lambda x: x.reshape(28*28))\n",
    "                        ]),\n",
    "                        target_transform=transforms.Compose([\n",
    "                            transforms.Lambda(lambda y: \n",
    "                                              torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    "                        ])\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_digits(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Use the nn package to define our model and loss function.\n",
    "model = CNN()\n",
    "model = model.to(device)\n",
    "\n",
    "cost = torch.nn.BCELoss()\n",
    "\n",
    "# optimizer which Tensors it should update.\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = StepLR(optimizer, 3)\n",
    "\n",
    "# dataset!\n",
    "dataloader = DataLoader(digits, batch_size=64, num_workers=0, pin_memory=True)\n",
    "\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for t in range(epochs):\n",
    "    print('\\nepoch {}, (lr: {:>.1e})'.format(t, scheduler.get_lr()[0]))\n",
    "    print('-------------------------------')\n",
    "    for batch, (X, Y) in enumerate(dataloader):\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss = cost(pred, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            print('loss: {:>10f}  [{:>5d}/{:>5d}]'.format(loss.item(), batch * len(X), len(dataloader.dataset)))\n",
    "            \n",
    "    # step scheduler\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does it work???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.MNIST('data', train=False, download=True,\n",
    "                        transform=transforms.Compose([\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Lambda(lambda x: x.reshape(28*28))\n",
    "                        ]),\n",
    "                        target_transform=transforms.Compose([\n",
    "                            transforms.Lambda(lambda y: \n",
    "                                              torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    "                        ])\n",
    "                     )\n",
    "test_loader = DataLoader(digits, batch_size=64, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for batch, (X, Y) in enumerate(test_loader):\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        pred = model(X)\n",
    "\n",
    "        test_loss += cost(pred, Y).item()\n",
    "        correct += (pred.argmax(1) == Y.argmax(1)).type(torch.float).sum().item()\n",
    "\n",
    "test_loss /= len(dataloader.dataset)\n",
    "correct /= len(dataloader.dataset)\n",
    "print('Test Error:')\n",
    "print('acc: {:>0.1f}%, avg loss: {:>8f}'.format(100*correct, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Things!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx as onnx\n",
    "\n",
    "# create dummy variable to traverse graph\n",
    "x = torch.randint(255, (1, 28*28), dtype=torch.float).to(device) / 255\n",
    "onnx.export(model, x, 'superfile.onnx')\n",
    "print('Saved onnx model to \"superfile.onnx\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
